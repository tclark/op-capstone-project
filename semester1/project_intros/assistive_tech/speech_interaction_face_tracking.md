**Extending speech interaction with gaze interaction **

**Overview**

This project has the end goal of creating a plug-in for a speech
recognition engine that enhances the speech interaction by adding face
tracking capabilities.

**Background**

Users with motor impairment find it difficult to interact with
electronic devices. Speech interaction circumvents some of the problems
faced by users with motor disability . However, in many situations, the
technology is far from ideal. This project proposes to enhance speech
interaction with face tracking capabilities. Speech recognition often
requires turning on and off the microphone in order to avoid false
positives while interacting with a computer. Such requirement often
involves the usage of the hands for pressing a key to turn the
microphone on and off. This obviously defeats the purpose of hands-free
interaction. This project would propose to circumvent the need to
manually activate an on-off switch by monitoring the face of a user
during computer interaction and turning on the microphone or passing
commands to the speech recognition engine only when the user is moving
the lips.

A reliable deformable face tracker can be found at:

<https://www.beyond-reality-face.com/techdemo?m=ft&dfsv=1&d3d=0&ce=0&aue=0>

![](media/image1.png)

**Deliverables**

-   a plug-in module for existing speech interaction software such as
    Dragon NaturallySpeaking, Windows speech recognition or Google
    speech API that enhances its functionality by adding face tracking
    functionality resulting in the user not needing to manually turn on
    and off the microphone to initiate interaction.
